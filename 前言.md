# 前言
早在 2012 年，雅虎！团队正在寻找一个全球性的地理复制平台，可以在各种应用程序（如雅虎邮件和雅虎财经）之间传输雅虎的所有消息数据。当时，通常有两种类型的系统来处理动态数据：实时处理关键业务事件的消息队列，以及大规模处理可扩展数据管道的流系统。但是没有一个平台可以同时提供雅虎所需的两种功能。

在审查消息传递和流媒体环境后，很明显现有技术无法满足他们的需求，因此 Yahoo!开始致力于为名为 Pulsar 的动态数据构建统一的消息传递和流媒体平台。在每天处理数十亿条消息的 10 个数据中心运行 4 年后，Yahoo! 2016 年决定在 Apache 许可下开源其消息传递平台。

我第一次接触 Pulsar 是在 2017 年秋天。我领导 Hortonworks 的专业服务团队，专注于名为 Hortonworks Data Flow (HDF) 的流数据平台，该平台由 Apache NiFi、Kafka 和 Storm 组成。我的工作是监督这些技术在客户基础设施中的部署，并帮助他们开始开发流媒体应用程序。

我们在使用 Kafka 时面临的最大挑战是帮助我们的客户正确管理它，特别是为给定主题确定适当的分区数量，以实现速度和效率的适当平衡，同时允许未来的数据增长。熟悉 Kafka 的人都痛苦地意识到，这个看似简单的决定对主题的可扩展性有着深远的影响，并且改变这个值的过程（甚至从 3 到 4）需要一个重新平衡的过程，它是慢，导致整个过程中无法读取或写入重新平衡的主题。

所有使用 HDF 的客户普遍不喜欢这种重新平衡要求，这是理所当然的，因为他们认为随着数据量的增长，这明显阻碍了他们扩展 Kafka 集群的能力。他们从经验中知道向上和向下扩展他们的消息传递平台是多么困难。更糟糕的是，我们不能简单地“插入”几个节点来为我们客户的现有集群增加计算能力，而无需通过为现有主题分配更多分区来重新配置主题来使用它们，从而将数据重新分配到最近添加的节点。这种在没有手动（或大量脚本）干预的情况下无法横向扩展其流媒体容量的情况与我们大多数客户将其消息传递平台迁移到云并利用云提供的弹性计算能力的愿望直接冲突。

那时我发现了 Apache Pulsar 平台，并发现它声称“云原生”特别有吸引力，因为它解决了可扩展性的两个痛点。虽然 HDF 使我的客户能够快速上手，但他们发现很难管理，而且其架构也无法在云中运行。我意识到 Apache Pulsar 是比我们目前提供给客户的解决方案更好的解决方案，并试图说服我们的产品团队考虑在我们的 HDF 产品中用 Pulsar 替换 Kafka。我什至编写了连接器，允许它与我们堆栈的 Apache NiFi 组件一起工作，以促进采用，但无济于事。

当 2018 年 1 月 Apache Pulsar 的原始开发人员与我接触并提供机会加入一家名为 Streamlio 的小型初创公司时，我立即抓住了与他们合作的机会。那时 Pulsar 是一个年轻的项目，刚刚进入 Apache 孵化计划，我们在接下来的 15 个月里努力让我们刚刚起步的“podling”通过孵化过程并晋升为顶级项目状态。

那是在流数据炒作的高峰期，而 Kafka 是该领域的主导者，所以每个人都认为这两个术语是可以互换的。共识是 Kafka 是唯一可用的数据流平台。我从之前的经历中知道得更清楚，并自己坚持不懈地传播我所知道的技术上优越的解决方案——一个在众所周知的荒野中喊叫的孤独的声音。

到 2019 年春天，Apache Pulsar 社区在贡献者和用户方面经历了巨大的增长，但严重缺乏有关该技术的可靠文档。因此，当第一次向我提出编写 Apache Pulsar in Action 的前景时，我立即将其视为解决 Pulsar 社区内明显需求的机会。虽然我始终无法说服我的同事加入我的行列，但他们在整个过程中提供了宝贵的指导和信息来源，并使用本书作为将他们的一些知识传授给您的一种方式。

本书面向 Pulsar 的新手，结合了我在项目创始人积极开发 Pulsar 时直接与他们合作时收集的信息，以及直接与采用 Apache Pulsar 的组织合作所获得的经验在生产中。

它旨在为其他人在使用 Pulsar 的过程中遇到的绊脚石和陷阱提供指导。最重要的是，本书将使您有信心使用 Java 编程语言开发采用 Pulsar 的流处理应用程序和微服务。尽管由于我对 Java 的熟悉，我选择在整本书的大部分代码示例中使用 Java，但我也使用 Python 创建了一组类似的代码并将其上传到我的 GitHub 帐户，供喜欢的人使用用那种语言编码。